{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9189e8ee",
   "metadata": {},
   "source": [
    "# Step 0\n",
    "## Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4969f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracing information from pdf\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# splitting & embedding\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# vector db\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# allow me to execute bash commands\n",
    "import os\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b62708",
   "metadata": {},
   "source": [
    "## Step 1: \n",
    "### Extract text from text books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f1ee531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file:  5G_mobile_communication_concepts.pdf\n",
      "Reading file:  5G_wireless.pdf\n",
      "Converting file:  content/5G_mobile_communication_concepts.pdf\n",
      "Converting file:  content/5G_wireless.pdf\n",
      "The total page of the textbooks are :  939\n",
      "The total number of words are :  2415197\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pdf_folder_path = \"content/\"\n",
    "\n",
    "loaders = []\n",
    "for file in os.listdir(pdf_folder_path):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        print(\"Reading file: \", file)\n",
    "        loaders.append(PyPDFLoader(os.path.join(pdf_folder_path, file)))\n",
    "\n",
    "def load_pdf(loaders):\n",
    "    full_documents = []\n",
    "    for loader in loaders:\n",
    "        print(\"Converting file: \", loader.file_path)\n",
    "        documents = loader.load()\n",
    "        full_documents.extend(documents)\n",
    "    return full_documents\n",
    "\n",
    "def convert_to_text(documents):\n",
    "    full_text = \"\"\n",
    "    for document in documents:\n",
    "        if len(document.page_content) > 20:\n",
    "            full_text += document.page_content\n",
    "    return full_text\n",
    "    \n",
    "\n",
    "\n",
    "full_documents = load_pdf(loaders)\n",
    "print(\"The total page of the textbooks are : \", len(full_documents))\n",
    "full_text = convert_to_text(full_documents)\n",
    "print(\"The total number of words are : \", len(full_text))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89243286",
   "metadata": {},
   "source": [
    "# Step 2:\n",
    "## Preprocessing, clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c963908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of words after cleaning are :  2405960\n"
     ]
    }
   ],
   "source": [
    "def remove_extra_spaces(text):\n",
    "    text = re.sub(r'\\n\\s*\\n', '\\n\\n', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "def clean_text(text):\n",
    "    cleaned_lines = []\n",
    "    lines = text.split(\"\\n\")\n",
    "    for line in lines:\n",
    "        line = remove_extra_spaces(line)\n",
    "        cleaned_lines.append(line)\n",
    "    cleaned_text = \"\\n\".join(cleaned_lines)\n",
    "    return cleaned_text\n",
    "\n",
    "clean_texted_text = clean_text(full_text)\n",
    "print(\"The total number of words after cleaning are : \", len(clean_texted_text))\n",
    "\n",
    "file_name = \"cleaned_text.txt\"\n",
    "with open(file_name, 'w', encoding='utf-8') as f:\n",
    "    f.write(clean_texted_text)\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2e9909",
   "metadata": {},
   "source": [
    "## Step 3:\n",
    "### Splitting texts into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c72ee17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of chunks are :  6061\n",
      "The vector db is saved in the faiss_index folder\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "with open('cleaned_text.txt', 'r', encoding='utf-8') as f:\n",
    "    clean_texted_text = f.read()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_text(clean_texted_text)\n",
    "print(\"The total number of chunks are : \", len(chunks))\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "vector_db = FAISS.from_texts(\n",
    "    texts = [chunk for chunk in chunks],\n",
    "    embedding = embeddings,\n",
    ")\n",
    "\n",
    "vector_db.save_local(\"faiss_index\")\n",
    "print(\"The vector db is saved in the faiss_index folder\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b1710c",
   "metadata": {},
   "source": [
    "## Step 4:\n",
    "### Query Processing & Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc3e7e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrive_context(query, k=3, score_threshold=0.8):\n",
    "    retrieved_context = vector_db.similarity_search(\n",
    "        query,\n",
    "        k = k,\n",
    "        score_threshold = score_threshold\n",
    "    )\n",
    "    return retrieved_context\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33fe468",
   "metadata": {},
   "source": [
    "## Step 5:\n",
    "### Generting Answer with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a59036cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "llm = OllamaLLM(model='llama3')\n",
    "\n",
    "def answer_question(question, context, llm):\n",
    "    # Reformat context\n",
    "    formatted_context = \"\\n\".join([doc.page_content for doc in context])\n",
    "\n",
    "    # Prompt Template\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert research assistant specializing in answering questions about research papers.\n",
    "\n",
    "    Task: Answer the question based on the provided context, with detail explaination and reasoning.\n",
    "\n",
    "    Instructions:\n",
    "    * Be concise and accurate.\n",
    "    * If the context does not contain the answer, say EXACTLY \"I cannot answer confidently\"\n",
    "    * If the question is unrelated to the context, say EXACTLY \"NA\"\n",
    "    * If the question asks for a yes/no answer, provide it and explain your reasoning shortly.\n",
    "\n",
    "    Context:\n",
    "    {formatted_context}\n",
    "\n",
    "    Question:\n",
    "    {question}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate answer using the LLM\n",
    "    try:\n",
    "        response = llm.invoke(prompt)  # Use the llm object directly\n",
    "        return response.strip() # Remove leading/trailing whitespace\n",
    "    except Exception as e:\n",
    "        print(f\"Error during LLM call: {e}\")\n",
    "        return \"Error processing the request.\"\n",
    "\n",
    "def response(query, k=10, score_threshold=0.8):\n",
    "    retrieved_context = retrive_context(query, k=k, score_threshold=score_threshold)\n",
    "    if not retrieved_context:\n",
    "        return \"No relevant context found.\"\n",
    "    \n",
    "    # Answer the question using the LLM\n",
    "    response = answer_question(query, retrieved_context, llm)\n",
    "    return response\n",
    "\n",
    "\n",
    "# while True:\n",
    "#     query = input(\"Enter your question:\")\n",
    "#     if query.upper() == (\"QUIT\") or query.upper() == (\"EXIT\"):\n",
    "#         print(\"Exiting the program\")\n",
    "#         break\n",
    "#     if query == \"\":\n",
    "#         print(\"Please enter a valid question\")\n",
    "#         continue\n",
    "#     answer = response(query, k=10, score_threshold=0.8)\n",
    "#     print(\"The answer is : \", answer)\n",
    "#     print(\"\\n\", \"type 'quit' or 'exit' to stop the program\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecbe167",
   "metadata": {},
   "source": [
    "## Step 5:\n",
    "#### Creating an UI for ease to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8098c211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import scrolledtext\n",
    "from threading import Thread\n",
    "\n",
    "\n",
    "def generate_and_display(user_input):\n",
    "    response = generate_answer(user_input)\n",
    "\n",
    "    # Update UI on main thread using after()\n",
    "    root.after(0, lambda: display_response(response))\n",
    "\n",
    "def display_response(response):\n",
    "    chat_log.config(state=tk.NORMAL)\n",
    "    chat_log.insert(tk.END, f\"AI: {response}\\n\\n\", \"bot\")\n",
    "    chat_log.config(state=tk.DISABLED)\n",
    "    chat_log.see(tk.END)\n",
    "\n",
    "def generate_answer(query, k=10, score_threshold=0.8):\n",
    "    retrieved_context = retrive_context(query, k=k, score_threshold=score_threshold)\n",
    "    if not retrieved_context:\n",
    "        return \"No relevant context found.\"\n",
    "\n",
    "    # Answer the question using the LLM\n",
    "    response = answer_question(query, retrieved_context, llm)\n",
    "    return response\n",
    "\n",
    "\n",
    "def send_message():\n",
    "    user_input = entry.get()\n",
    "    if not user_input.strip():\n",
    "        return\n",
    "    \n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        chat_log.config(state=tk.NORMAL)\n",
    "        chat_log.insert(tk.END, f\"You: {user_input}\\n\", \"user\")\n",
    "        chat_log.insert(tk.END, \"AI: Goodbye! 👋\\n\\n\", \"bot\")\n",
    "        chat_log.config(state=tk.DISABLED)\n",
    "        chat_log.see(tk.END)\n",
    "        root.after(3000, root.destroy)  # delay to let user see the message\n",
    "        return\n",
    "\n",
    "    chat_log.config(state=tk.NORMAL)\n",
    "    chat_log.insert(tk.END, \"You: \" + user_input + \"\\n\", \"user\")\n",
    "    chat_log.config(state=tk.DISABLED)\n",
    "    chat_log.see(tk.END)\n",
    "\n",
    "    entry.delete(0, tk.END)\n",
    "\n",
    "    Thread(target=generate_and_display, args=(user_input,)).start()\n",
    "\n",
    "# UI setup\n",
    "root = tk.Tk()\n",
    "root.title(\"RAG Chatbot\")\n",
    "\n",
    "# Frame for scrollbar and chat log\n",
    "frame = tk.Frame(root)\n",
    "frame.pack(padx=10, pady=10, fill=tk.BOTH, expand=True)\n",
    "\n",
    "scrollbar = tk.Scrollbar(frame)\n",
    "scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "\n",
    "chat_log = tk.Text(\n",
    "    frame, wrap=tk.WORD, state=tk.DISABLED, width=60, height=20, yscrollcommand=scrollbar.set\n",
    ")\n",
    "chat_log.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "scrollbar.config(command=chat_log.yview)\n",
    "\n",
    "# Define tag styles\n",
    "chat_log.tag_config(\"user\", foreground=\"blue\", font=(\"Arial\", 11, \"bold\"))\n",
    "chat_log.tag_config(\"bot\", foreground=\"green\", font=(\"Arial\", 11))\n",
    "\n",
    "entry = tk.Entry(root, width=50)\n",
    "entry.pack(side=tk.LEFT, padx=(10, 0), pady=(0, 10))\n",
    "entry.bind(\"<Return>\", lambda event: send_message())\n",
    "\n",
    "send_button = tk.Button(root, text=\"Send\", command=send_message)\n",
    "send_button.pack(side=tk.RIGHT, padx=(0, 10), pady=(0, 10))\n",
    "\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
